{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:52:56.771896Z",
     "start_time": "2025-01-06T13:52:56.754291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from tensorflow.python.ops.gen_nn_ops import LeakyRelu\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, RepeatVector, TimeDistributed, Input, LeakyReLU\n",
    "from keras.optimizers import Adam\n"
   ],
   "id": "34d4292b1b588460",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:52:56.945761Z",
     "start_time": "2025-01-06T13:52:56.920726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Functions\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss (MSE)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def check_stationarity(series):\n",
    "    adf_result = adfuller(series)\n",
    "    print(\"ADF Statistic:\", adf_result[0])\n",
    "    print(\"p-value:\", adf_result[1])\n",
    "    if adf_result[1] <= 0.05:\n",
    "        print(\"The series is stationary.\")\n",
    "    else:\n",
    "        print(\"The series is not stationary.\")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def window_generator(data, feature_columns, target_column, input_size, output_size, stride):\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    data = data.sort_index()\n",
    "\n",
    "    feature_scaler = MinMaxScaler()\n",
    "    target_scaler = MinMaxScaler()\n",
    "\n",
    "    scaled_features = feature_scaler.fit_transform(data[feature_columns])\n",
    "    scaled_target = target_scaler.fit_transform(data[target_column])\n",
    "\n",
    "    for start in range(0, len(data) - input_size - output_size + 1, stride):\n",
    "        end_input = start + input_size\n",
    "        end_output = end_input + output_size\n",
    "\n",
    "        X.append(scaled_features[start:end_input])\n",
    "        y.append(scaled_target[end_input:end_output])\n",
    "\n",
    "    return np.array(X), np.array(y), feature_scaler, target_scaler\n",
    "\n",
    "\n",
    "\n",
    "def test_window_generator(test_data, feature_columns, target_column, input_size, output_size, stride, feature_scaler, target_scaler):\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    test_data = test_data.sort_index()\n",
    "\n",
    "    scaled_features = feature_scaler.transform(test_data[feature_columns])\n",
    "    scaled_target = target_scaler.transform(test_data[target_column])\n",
    "\n",
    "    for start in range(0, len(test_data) - input_size - output_size + 1, stride):\n",
    "        end_input = start + input_size\n",
    "        end_output = end_input + output_size\n",
    "\n",
    "        X_test.append(scaled_features[start:end_input])\n",
    "        y_test.append(scaled_target[end_input:end_output])\n",
    "\n",
    "    return np.array(X_test), np.array(y_test)\n",
    "\n"
   ],
   "id": "c0286f15e59c4a77",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:52:57.315861Z",
     "start_time": "2025-01-06T13:52:57.058232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(14, 882)),  # Match input shape with your data\n",
    "    LSTM(50 , activation='tanh', return_sequences=True),\n",
    "    Dropout(0.2),  # Regularization\n",
    "    # First LSTM layer\n",
    "    LSTM(25, activation='tanh', return_sequences=True),\n",
    "    Dropout(0.2),  # Regularization\n",
    "\n",
    "    # Second LSTM layer\n",
    "    LSTM(10, activation='tanh', return_sequences=False),\n",
    "    Dropout(0.2),  # Regularization\n",
    "\n",
    "    # Fully connected output layer\n",
    "    Dense(2, activation='linear')  # Output layer for 2 features\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['MAE'])\n",
    "model.summary()"
   ],
   "id": "7470e6e6ab6892c2",
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential_2\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ lstm_6 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m50\u001B[0m)         │       \u001B[38;5;34m186,600\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m50\u001B[0m)         │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_7 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m25\u001B[0m)         │         \u001B[38;5;34m7,600\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m25\u001B[0m)         │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_8 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │         \u001B[38;5;34m1,440\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_8 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m)              │            \u001B[38;5;34m22\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">186,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,440</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m195,662\u001B[0m (764.30 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,662</span> (764.30 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m195,662\u001B[0m (764.30 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,662</span> (764.30 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T14:02:03.299589Z",
     "start_time": "2025-01-06T14:02:01.670012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ticker_data = pd.read_csv('ticker_data.csv')\n",
    "ticker_data['Date'] = pd.to_datetime(ticker_data['Unnamed: 0'])  # Ensure 'Date' is in datetime format\n",
    "ticker_data.set_index('Date', inplace=True)\n",
    "ticker_data.index = pd.to_datetime(ticker_data.index, utc=True)\n",
    "ticker_data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "# Example column names\n",
    "columns = ticker_data.columns.to_list()\n",
    "\n",
    "# Extract unique tickers from column names\n",
    "tickers = list(set(col.split('_')[1] for col in columns))\n",
    "\n",
    "random_tickers = random.sample(tickers, 2)\n",
    "\n",
    "X_columns = [f\"Volume_{ticker}\" for ticker in columns] + [f\"Price_Change_{ticker}\" for ticker in columns]\n",
    "y_columns = [f\"Price_Change_{ticker}\" for ticker in random_tickers]\n",
    "\n",
    "ticker_data.index = pd.to_datetime(ticker_data.index)\n",
    "\n",
    "train_data = ticker_data.loc['2010-01-01':'2018-01-01']\n",
    "test_data = ticker_data.loc['2018-01-01':'2020-01-01']\n",
    "X_train, y_train , feature_scaler, target_scaler = window_generator(train_data, columns, y_columns, 60, 1, 1)\n",
    "X_test , y_test = test_window_generator(test_data, columns, y_columns, 60, 1, 1, feature_scaler, target_scaler)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ],
   "id": "de6fdba0762134c2",
   "outputs": [
    {
     "data": {
      "text/plain": "((1718, 60, 882), (1718, 1, 2), (443, 60, 882), (443, 1, 2))"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "is_executing": true
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_tuner import RandomSearch\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Reshape\n",
    "\n",
    "def build_model(hp):\n",
    "    \"\"\"\n",
    "    Build a Sequential LSTM model dynamically based on hyperparameter choices.\n",
    "\n",
    "    Parameters:\n",
    "        hp: Hyperparameter object for dynamic tuning.\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras Sequential model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Input(shape=(60, 882)),  # Update input shape based on your data\n",
    "        LSTM(\n",
    "            units=hp.Int('lstm_units1', min_value=50, max_value=150, step=50),\n",
    "            activation='tanh',\n",
    "            return_sequences=True\n",
    "        ),\n",
    "        Dropout(rate=hp.Float('dropout_rate1', min_value=0.1, max_value=0.5, step=0.1)),\n",
    "        LSTM(\n",
    "            units=hp.Int('lstm_units2', min_value=25, max_value=75, step=25),\n",
    "            activation='relu',\n",
    "            return_sequences=False  # Collapse sequence\n",
    "        ),\n",
    "        Dropout(rate=hp.Float('dropout_rate2', min_value=0.1, max_value=0.5, step=0.1)),\n",
    "        Dense(7 * 2, activation='linear'),  # Output 7 * 2 values\n",
    "        Reshape((7, 2))  # Reshape to (7, 2)\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Choice('learning_rate', [0.001, 0.005, 0.01])),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['MAE']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Initialize Keras Tuner RandomSearch\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_MAE',\n",
    "    max_trials=20,  # Increase for more comprehensive search\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_results',\n",
    "    project_name='lstm_tuning_multi_stock',\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "X_train, y_train , feature_scaler, target_scaler = window_generator(train_data, columns, y_columns, 60, 7, 1)\n",
    "X_test , y_test = test_window_generator(test_data, columns, y_columns, 60, 7, 1, feature_scaler, target_scaler)\n",
    "\n",
    "# EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_MAE',\n",
    "    patience=2,\n",
    "    restore_best_weights=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    validation_split=0.2,\n",
    "    verbose=2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for param, value in best_hps.values.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "# Build the best model\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the best model\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Loss Plot\n",
    "    plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "    plt.title('Model Loss Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss (MSE)')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # MAE Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['MAE'], label='Training MAE', color='green')\n",
    "    plt.plot(history.history['val_MAE'], label='Validation MAE', color='red')\n",
    "    plt.title('Model MAE Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Mean Absolute Error')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "# Debugging: List all trials\n",
    "print(\"\\nAll Trials:\")\n",
    "for trial in tuner.oracle.get_best_trials():\n",
    "    print(f\"Trial ID: {trial.trial_id}\")\n",
    "    print(f\"Hyperparameters: {trial.hyperparameters.values}\")\n",
    "    print(f\"Score: {trial.score}\")"
   ],
   "id": "ad59a9adac9b7701",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 23s]\n",
      "val_MAE: 0.03738289698958397\n",
      "\n",
      "Best val_MAE So Far: 0.03496492654085159\n",
      "Total elapsed time: 00h 11m 16s\n",
      "\n",
      "Search: Running Trial #11\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "50                |150               |lstm_units1\n",
      "0.4               |0.1               |dropout_rate1\n",
      "75                |25                |lstm_units2\n",
      "0.4               |0.4               |dropout_rate2\n",
      "0.001             |0.005             |learning_rate\n",
      "Epoch 1/20\n",
      "43/43 - 5s - 116ms/step - MAE: 0.1955 - loss: 0.0628 - val_MAE: 0.0972 - val_loss: 0.0121\n",
      "Epoch 2/20\n",
      "43/43 - 3s - 65ms/step - MAE: 0.1233 - loss: 0.0245 - val_MAE: 0.0772 - val_loss: 0.0080\n",
      "Epoch 3/20\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T14:14:36.992576Z",
     "start_time": "2025-01-06T14:14:36.983424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for trial_id, trial in tuner.oracle.trials.items():\n",
    "    print(f\"Trial ID: {trial_id}\")\n",
    "    print(f\"Hyperparameters: {trial.hyperparameters.values}\")\n",
    "    print(f\"Score: {trial.score}\")"
   ],
   "id": "df2a9f076340a99f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial ID: 00\n",
      "Hyperparameters: {'lstm_units1': 150, 'dropout_rate1': 0.5, 'lstm_units2': 75, 'dropout_rate2': 0.5, 'lstm_units3': 40, 'learning_rate': 0.01}\n",
      "Score: 0.2517491281032562\n",
      "Trial ID: 01\n",
      "Hyperparameters: {'lstm_units1': 50, 'dropout_rate1': 0.30000000000000004, 'lstm_units2': 50, 'dropout_rate2': 0.1, 'lstm_units3': 10, 'learning_rate': 0.005}\n",
      "Score: 0.2748723030090332\n",
      "Trial ID: 02\n",
      "Hyperparameters: {'lstm_units1': 50, 'dropout_rate1': 0.4, 'lstm_units2': 75, 'dropout_rate2': 0.1, 'lstm_units3': 50, 'learning_rate': 0.01}\n",
      "Score: 0.25560158491134644\n",
      "Trial ID: 03\n",
      "Hyperparameters: {'lstm_units1': 150, 'dropout_rate1': 0.1, 'lstm_units2': 50, 'dropout_rate2': 0.1, 'lstm_units3': 50, 'learning_rate': 0.005}\n",
      "Score: 0.2594822645187378\n",
      "Trial ID: 04\n",
      "Hyperparameters: {'lstm_units1': 100, 'dropout_rate1': 0.4, 'lstm_units2': 25, 'dropout_rate2': 0.30000000000000004, 'lstm_units3': 10, 'learning_rate': 0.01}\n",
      "Score: 0.2589743733406067\n",
      "Trial ID: 05\n",
      "Hyperparameters: {'lstm_units1': 50, 'dropout_rate1': 0.1, 'lstm_units2': 50, 'dropout_rate2': 0.2, 'lstm_units3': 20, 'learning_rate': 0.005}\n",
      "Score: 0.26607605814933777\n",
      "Trial ID: 06\n",
      "Hyperparameters: {'lstm_units1': 100, 'dropout_rate1': 0.4, 'lstm_units2': 25, 'dropout_rate2': 0.4, 'lstm_units3': 50, 'learning_rate': 0.001}\n",
      "Score: 0.2646905183792114\n",
      "Trial ID: 07\n",
      "Hyperparameters: {'lstm_units1': 100, 'dropout_rate1': 0.2, 'lstm_units2': 75, 'dropout_rate2': 0.1, 'lstm_units3': 40, 'learning_rate': 0.001}\n",
      "Score: 0.2656642496585846\n",
      "Trial ID: 08\n",
      "Hyperparameters: {'lstm_units1': 50, 'dropout_rate1': 0.1, 'lstm_units2': 25, 'dropout_rate2': 0.2, 'lstm_units3': 50, 'learning_rate': 0.01}\n",
      "Score: 0.2684463858604431\n",
      "Trial ID: 09\n",
      "Hyperparameters: {'lstm_units1': 50, 'dropout_rate1': 0.1, 'lstm_units2': 50, 'dropout_rate2': 0.5, 'lstm_units3': 40, 'learning_rate': 0.01}\n",
      "Score: 0.258493572473526\n",
      "Trial ID: 10\n",
      "Hyperparameters: {'lstm_units1': 50, 'dropout_rate1': 0.2, 'lstm_units2': 75, 'dropout_rate2': 0.30000000000000004, 'lstm_units3': 20, 'learning_rate': 0.005}\n",
      "Score: 0.25312790274620056\n",
      "Trial ID: 11\n",
      "Hyperparameters: {'lstm_units1': 50, 'dropout_rate1': 0.1, 'lstm_units2': 75, 'dropout_rate2': 0.1, 'lstm_units3': 30, 'learning_rate': 0.005}\n",
      "Score: 0.25289908051490784\n",
      "Trial ID: 12\n",
      "Hyperparameters: {'lstm_units1': 150, 'dropout_rate1': 0.4, 'lstm_units2': 50, 'dropout_rate2': 0.30000000000000004, 'lstm_units3': 20, 'learning_rate': 0.005}\n",
      "Score: 0.24764522910118103\n",
      "Trial ID: 13\n",
      "Hyperparameters: {'lstm_units1': 150, 'dropout_rate1': 0.30000000000000004, 'lstm_units2': 25, 'dropout_rate2': 0.2, 'lstm_units3': 20, 'learning_rate': 0.01}\n",
      "Score: 0.2512451410293579\n",
      "Trial ID: 14\n",
      "Hyperparameters: {'lstm_units1': 50, 'dropout_rate1': 0.2, 'lstm_units2': 50, 'dropout_rate2': 0.30000000000000004, 'lstm_units3': 30, 'learning_rate': 0.005}\n",
      "Score: 0.26798778772354126\n",
      "Trial ID: 15\n",
      "Hyperparameters: {'lstm_units1': 100, 'dropout_rate1': 0.4, 'lstm_units2': 50, 'dropout_rate2': 0.4, 'lstm_units3': 40, 'learning_rate': 0.001}\n",
      "Score: 0.26971593499183655\n",
      "Trial ID: 16\n",
      "Hyperparameters: {'lstm_units1': 100, 'dropout_rate1': 0.1, 'lstm_units2': 50, 'dropout_rate2': 0.4, 'lstm_units3': 20, 'learning_rate': 0.005}\n",
      "Score: 0.2960081696510315\n",
      "Trial ID: 17\n",
      "Hyperparameters: {'lstm_units1': 150, 'dropout_rate1': 0.1, 'lstm_units2': 75, 'dropout_rate2': 0.4, 'lstm_units3': 30, 'learning_rate': 0.005}\n",
      "Score: 0.26155179738998413\n",
      "Trial ID: 18\n",
      "Hyperparameters: {'lstm_units1': 100, 'dropout_rate1': 0.1, 'lstm_units2': 50, 'dropout_rate2': 0.4, 'lstm_units3': 30, 'learning_rate': 0.01}\n",
      "Score: 0.25124093890190125\n",
      "Trial ID: 19\n",
      "Hyperparameters: {'lstm_units1': 100, 'dropout_rate1': 0.30000000000000004, 'lstm_units2': 25, 'dropout_rate2': 0.1, 'lstm_units3': 10, 'learning_rate': 0.01}\n",
      "Score: 0.24865631759166718\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:52:50.755622Z",
     "start_time": "2025-01-06T13:52:50.754585Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "382961027d714a53"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
