{
 "cells": [
  {
   "cell_type": "code",
   "id": "bbdb01e399d2edce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T20:27:33.002336Z",
     "start_time": "2025-01-04T20:27:32.997046Z"
    }
   },
   "source": [
    "import yfinance as yf\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T20:29:21.039022Z",
     "start_time": "2025-01-04T20:27:34.450293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Read ticker symbols from file\n",
    "with open(\"tickers.txt\", \"r\") as file:\n",
    "    tickers = [line.strip() for line in file]\n",
    "\n",
    "# Create an empty CSV file with headers to store data\n",
    "output_file = \"sp500_data.csv\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(\"Ticker,Date, Volume,Price_Change\\n\")  # Define headers\n",
    "\n",
    "# Fetch historical data for all tickers and write iteratively\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        print(f\"Fetching data for {ticker}...\")\n",
    "        stock = yf.Ticker(ticker)\n",
    "        index = stock.history(start=\"2010-01-01\", end=\"2020-12-31\")\n",
    "\n",
    "        # Check if the data is complete (all dates from 2010-01-01 to 2020-12-31)\n",
    "        if index.empty:\n",
    "            print(f\"No data for {ticker}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Calculate expected number of trading days (approx. 252 days/year)\n",
    "        expected_days = 252 * 10  # 10 years of trading data\n",
    "        if len(index) < expected_days:\n",
    "            print(f\"Incomplete data for {ticker} ({len(index)} days). Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Calculate percentage price change\n",
    "        index['Price_Change'] = index['Close'].pct_change()\n",
    "\n",
    "        # Reset index to make 'Date' a column\n",
    "        index.reset_index(inplace=True)\n",
    "        index['Ticker'] = ticker  # Add a column for the ticker symbol\n",
    "\n",
    "        # Select relevant columns and write to the CSV file in append mode\n",
    "        index[['Ticker', 'Date', 'Volume', 'Price_Change']].to_csv(\n",
    "            output_file, mode='a', header=False, index=False\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch data for {ticker}: {e}\")\n",
    "print(f\"Data collection complete! Saved to {output_file}.\")"
   ],
   "id": "cdcfe2e1283cd21b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for EQIX...\n",
      "Fetching data for STLD...\n",
      "Fetching data for GPC...\n",
      "Fetching data for BKNG...\n",
      "Fetching data for CSX...\n",
      "Fetching data for AON...\n",
      "Fetching data for BLK...\n",
      "Fetching data for TJX...\n",
      "Fetching data for IRM...\n",
      "Fetching data for ELV...\n",
      "Fetching data for ANET...\n",
      "Incomplete data for ANET (1655 days). Skipping...\n",
      "Fetching data for LVS...\n",
      "Fetching data for PCG...\n",
      "Fetching data for FAST...\n",
      "Fetching data for GLW...\n",
      "Fetching data for CNC...\n",
      "Fetching data for TPR...\n",
      "Fetching data for CL...\n",
      "Fetching data for PWR...\n",
      "Fetching data for FDX...\n",
      "Fetching data for ROST...\n",
      "Fetching data for WDC...\n",
      "Fetching data for V...\n",
      "Fetching data for AMD...\n",
      "Fetching data for PM...\n",
      "Fetching data for NVR...\n",
      "Fetching data for J...\n",
      "Fetching data for KDP...\n",
      "Fetching data for TSLA...\n",
      "Fetching data for PHM...\n",
      "Fetching data for HD...\n",
      "Fetching data for KEYS...\n",
      "Incomplete data for KEYS (1561 days). Skipping...\n",
      "Fetching data for LW...\n",
      "Incomplete data for LW (1041 days). Skipping...\n",
      "Fetching data for RCL...\n",
      "Fetching data for DLTR...\n",
      "Fetching data for ENPH...\n",
      "Incomplete data for ENPH (2203 days). Skipping...\n",
      "Fetching data for COP...\n",
      "Fetching data for ORCL...\n",
      "Fetching data for PSX...\n",
      "Incomplete data for PSX (2195 days). Skipping...\n",
      "Fetching data for AEP...\n",
      "Fetching data for CTSH...\n",
      "Fetching data for ES...\n",
      "Fetching data for PRU...\n",
      "Fetching data for BA...\n",
      "Fetching data for CAT...\n",
      "Fetching data for AWK...\n",
      "Fetching data for EPAM...\n",
      "Incomplete data for EPAM (2239 days). Skipping...\n",
      "Fetching data for TYL...\n",
      "Fetching data for DPZ...\n",
      "Fetching data for JPM...\n",
      "Fetching data for MCO...\n",
      "Fetching data for PCAR...\n",
      "Fetching data for ISRG...\n",
      "Fetching data for A...\n",
      "Fetching data for BKR...\n",
      "Fetching data for NTRS...\n",
      "Fetching data for STX...\n",
      "Fetching data for ZBRA...\n",
      "Fetching data for TRMB...\n",
      "Fetching data for KMB...\n",
      "Fetching data for XYL...\n",
      "Incomplete data for XYL (2319 days). Skipping...\n",
      "Fetching data for CAG...\n",
      "Fetching data for BBWI...\n",
      "Fetching data for TROW...\n",
      "Fetching data for FRT...\n",
      "Fetching data for TRGP...\n",
      "Fetching data for IVZ...\n",
      "Fetching data for NDSN...\n",
      "Fetching data for CPB...\n",
      "Fetching data for TFC...\n",
      "Fetching data for TMUS...\n",
      "Fetching data for WM...\n",
      "Fetching data for MKTX...\n",
      "Fetching data for MLM...\n",
      "Fetching data for IT...\n",
      "Fetching data for ADM...\n",
      "Fetching data for BK...\n",
      "Fetching data for DVA...\n",
      "Fetching data for INTC...\n",
      "Fetching data for F...\n",
      "Fetching data for GPN...\n",
      "Fetching data for USB...\n",
      "Fetching data for CSCO...\n",
      "Fetching data for WEC...\n",
      "Fetching data for WHR...\n",
      "Fetching data for LYB...\n",
      "Fetching data for CTLT...\n",
      "Incomplete data for CTLT (1617 days). Skipping...\n",
      "Fetching data for MOH...\n",
      "Fetching data for BR...\n",
      "Fetching data for COST...\n",
      "Fetching data for ADSK...\n",
      "Fetching data for CVX...\n",
      "Fetching data for PTC...\n",
      "Fetching data for VTR...\n",
      "Fetching data for JKHY...\n",
      "Fetching data for TTWO...\n",
      "Fetching data for WMB...\n",
      "Fetching data for CDNS...\n",
      "Fetching data for CPRT...\n",
      "Fetching data for AJG...\n",
      "Fetching data for VMC...\n",
      "Fetching data for CVS...\n",
      "Fetching data for AIG...\n",
      "Fetching data for UHS...\n",
      "Fetching data for AKAM...\n",
      "Fetching data for SRE...\n",
      "Fetching data for SLB...\n",
      "Fetching data for SJM...\n",
      "Fetching data for ANSS...\n",
      "Fetching data for AZO...\n",
      "Fetching data for HRL...\n",
      "Fetching data for COO...\n",
      "Fetching data for AES...\n",
      "Fetching data for PPL...\n",
      "Fetching data for CRM...\n",
      "Fetching data for AAPL...\n",
      "Fetching data for SEDG...\n",
      "Incomplete data for SEDG (1453 days). Skipping...\n",
      "Fetching data for CSGP...\n",
      "Fetching data for QRVO...\n",
      "Incomplete data for QRVO (1510 days). Skipping...\n",
      "Fetching data for CMG...\n",
      "Fetching data for FIS...\n",
      "Fetching data for CDW...\n",
      "Incomplete data for CDW (1892 days). Skipping...\n",
      "Fetching data for BSX...\n",
      "Fetching data for KR...\n",
      "Fetching data for SWKS...\n",
      "Fetching data for FANG...\n",
      "Incomplete data for FANG (2067 days). Skipping...\n",
      "Fetching data for AXON...\n",
      "Fetching data for MGM...\n",
      "Fetching data for NDAQ...\n",
      "Fetching data for IBM...\n",
      "Fetching data for SBUX...\n",
      "Fetching data for CE...\n",
      "Fetching data for TDY...\n",
      "Fetching data for WYNN...\n",
      "Fetching data for EXPD...\n",
      "Fetching data for WAT...\n",
      "Fetching data for ON...\n",
      "Fetching data for IEX...\n",
      "Fetching data for WFC...\n",
      "Fetching data for HII...\n",
      "Incomplete data for HII (2462 days). Skipping...\n",
      "Fetching data for LNT...\n",
      "Fetching data for ATO...\n",
      "Fetching data for PODD...\n",
      "Fetching data for ALGN...\n",
      "Fetching data for WAB...\n",
      "Fetching data for STT...\n",
      "Fetching data for MTD...\n",
      "Fetching data for AVB...\n",
      "Fetching data for RHI...\n",
      "Fetching data for WST...\n",
      "Fetching data for SNA...\n",
      "Fetching data for ECL...\n",
      "Fetching data for HOLX...\n",
      "Fetching data for ZION...\n",
      "Fetching data for VRSN...\n",
      "Fetching data for D...\n",
      "Fetching data for FITB...\n",
      "Fetching data for CRL...\n",
      "Fetching data for PAYC...\n",
      "Incomplete data for PAYC (1691 days). Skipping...\n",
      "Fetching data for JBHT...\n",
      "Fetching data for CMI...\n",
      "Fetching data for HUM...\n",
      "Fetching data for DGX...\n",
      "Fetching data for XEL...\n",
      "Fetching data for AXP...\n",
      "Fetching data for BMY...\n",
      "Fetching data for CAH...\n",
      "Fetching data for MCHP...\n",
      "Fetching data for GE...\n",
      "Fetching data for DUK...\n",
      "Fetching data for MO...\n",
      "Fetching data for HON...\n",
      "Fetching data for NSC...\n",
      "Fetching data for URI...\n",
      "Fetching data for WMT...\n",
      "Fetching data for EMR...\n",
      "Fetching data for PEG...\n",
      "Fetching data for NI...\n",
      "Fetching data for HPQ...\n",
      "Fetching data for CCI...\n",
      "Fetching data for OXY...\n",
      "Fetching data for MA...\n",
      "Fetching data for AIZ...\n",
      "Fetching data for PG...\n",
      "Fetching data for TSCO...\n",
      "Fetching data for NTAP...\n",
      "Fetching data for PEP...\n",
      "Fetching data for MSCI...\n",
      "Fetching data for MMM...\n",
      "Fetching data for JCI...\n",
      "Fetching data for LUV...\n",
      "Fetching data for WTW...\n",
      "Fetching data for NEE...\n",
      "Fetching data for K...\n",
      "Fetching data for INCY...\n",
      "Fetching data for BAC...\n",
      "Fetching data for APH...\n",
      "Fetching data for KLAC...\n",
      "Fetching data for LMT...\n",
      "Fetching data for KEY...\n",
      "Fetching data for BBY...\n",
      "Fetching data for HAL...\n",
      "Fetching data for OKE...\n",
      "Fetching data for KHC...\n",
      "Incomplete data for KHC (1384 days). Skipping...\n",
      "Fetching data for MAA...\n",
      "Fetching data for ABT...\n",
      "Fetching data for SWK...\n",
      "Fetching data for PNR...\n",
      "Fetching data for DTE...\n",
      "Fetching data for NRG...\n",
      "Fetching data for FE...\n",
      "Fetching data for TT...\n",
      "Fetching data for VRSK...\n",
      "Fetching data for UDR...\n",
      "Fetching data for ZBH...\n",
      "Fetching data for JNPR...\n",
      "Fetching data for VLO...\n",
      "Fetching data for YUM...\n",
      "Fetching data for DAL...\n",
      "Fetching data for LYV...\n",
      "Fetching data for AMZN...\n",
      "Fetching data for IP...\n",
      "Fetching data for DLR...\n",
      "Fetching data for FFIV...\n",
      "Fetching data for ULTA...\n",
      "Fetching data for ADI...\n",
      "Fetching data for DXCM...\n",
      "Fetching data for EOG...\n",
      "Fetching data for ETSY...\n",
      "Incomplete data for ETSY (1439 days). Skipping...\n",
      "Fetching data for PFE...\n",
      "Fetching data for EXR...\n",
      "Fetching data for MTCH...\n",
      "Fetching data for GS...\n",
      "Fetching data for AOS...\n",
      "Fetching data for O...\n",
      "Fetching data for NUE...\n",
      "Fetching data for GNRC...\n",
      "Fetching data for DFS...\n",
      "Fetching data for ADBE...\n",
      "Fetching data for NVDA...\n",
      "Fetching data for ODFL...\n",
      "Fetching data for ALB...\n",
      "Fetching data for EA...\n",
      "Fetching data for KMX...\n",
      "Fetching data for ALL...\n",
      "Fetching data for CB...\n",
      "Fetching data for AEE...\n",
      "Fetching data for MAR...\n",
      "Fetching data for REGN...\n",
      "Fetching data for NCLH...\n",
      "Incomplete data for NCLH (2002 days). Skipping...\n",
      "Fetching data for WBA...\n",
      "Fetching data for EMN...\n",
      "Fetching data for EL...\n",
      "Fetching data for ROK...\n",
      "Fetching data for TECH...\n",
      "Fetching data for FTNT...\n",
      "Fetching data for TFX...\n",
      "Fetching data for HSY...\n",
      "Fetching data for VFC...\n",
      "Fetching data for LEN...\n",
      "Fetching data for COR...\n",
      "Fetching data for VTRS...\n",
      "Fetching data for UAL...\n",
      "Fetching data for CTRA...\n",
      "Fetching data for C...\n",
      "Fetching data for CMS...\n",
      "Fetching data for ARE...\n",
      "Fetching data for OMC...\n",
      "Fetching data for CMCSA...\n",
      "Fetching data for SPG...\n",
      "Fetching data for ROL...\n",
      "Fetching data for CI...\n",
      "Fetching data for EFX...\n",
      "Fetching data for HAS...\n",
      "Fetching data for LHX...\n",
      "Fetching data for LOW...\n",
      "Fetching data for APA...\n",
      "Fetching data for INTU...\n",
      "Fetching data for ABBV...\n",
      "Incomplete data for ABBV (2014 days). Skipping...\n",
      "Fetching data for MSI...\n",
      "Fetching data for CFG...\n",
      "Incomplete data for CFG (1579 days). Skipping...\n",
      "Fetching data for MDT...\n",
      "Fetching data for SYF...\n",
      "Incomplete data for SYF (1617 days). Skipping...\n",
      "Fetching data for DHI...\n",
      "Fetching data for EXC...\n",
      "Fetching data for PAYX...\n",
      "Fetching data for RTX...\n",
      "Fetching data for TGT...\n",
      "Fetching data for ETN...\n",
      "Fetching data for SYK...\n",
      "Fetching data for NOW...\n",
      "Incomplete data for NOW (2140 days). Skipping...\n",
      "Fetching data for EQT...\n",
      "Fetching data for BG...\n",
      "Fetching data for MOS...\n",
      "Fetching data for LKQ...\n",
      "Fetching data for NXPI...\n",
      "Fetching data for PH...\n",
      "Fetching data for MKC...\n",
      "Fetching data for XRAY...\n",
      "Fetching data for NKE...\n",
      "Fetching data for BAX...\n",
      "Fetching data for GL...\n",
      "Fetching data for PNC...\n",
      "Fetching data for WELL...\n",
      "Fetching data for CINF...\n",
      "Fetching data for APD...\n",
      "Fetching data for FDS...\n",
      "Fetching data for RMD...\n",
      "Fetching data for GOOG...\n",
      "Fetching data for DIS...\n",
      "Fetching data for NFLX...\n",
      "Fetching data for EVRG...\n",
      "Fetching data for FMC...\n",
      "Fetching data for REG...\n",
      "Fetching data for NEM...\n",
      "Fetching data for FI...\n",
      "Fetching data for RSG...\n",
      "Fetching data for CHRW...\n",
      "Fetching data for CLX...\n",
      "Fetching data for GD...\n",
      "Fetching data for ITW...\n",
      "Fetching data for AMT...\n",
      "Fetching data for STZ...\n",
      "Fetching data for APTV...\n",
      "Incomplete data for APTV (2294 days). Skipping...\n",
      "Fetching data for MET...\n",
      "Fetching data for JNJ...\n",
      "Fetching data for KMI...\n",
      "Incomplete data for KMI (2488 days). Skipping...\n",
      "Fetching data for IFF...\n",
      "Fetching data for DHR...\n",
      "Fetching data for T...\n",
      "Fetching data for IPG...\n",
      "Fetching data for HST...\n",
      "Fetching data for KIM...\n",
      "Fetching data for FTV...\n",
      "Incomplete data for FTV (1132 days). Skipping...\n",
      "Fetching data for MHK...\n",
      "Fetching data for SO...\n",
      "Fetching data for EG...\n",
      "Fetching data for LH...\n",
      "Fetching data for PNW...\n",
      "Fetching data for ACGL...\n",
      "Fetching data for TMO...\n",
      "Fetching data for SEE...\n",
      "Fetching data for PYPL...\n",
      "Incomplete data for PYPL (1384 days). Skipping...\n",
      "Fetching data for GIS...\n",
      "Fetching data for MSFT...\n",
      "Fetching data for AMP...\n",
      "Fetching data for MU...\n",
      "Fetching data for HES...\n",
      "Fetching data for TXT...\n",
      "Fetching data for BIO...\n",
      "Fetching data for FSLR...\n",
      "Fetching data for PARA...\n",
      "Fetching data for IQV...\n",
      "Incomplete data for IQV (1926 days). Skipping...\n",
      "Fetching data for SNPS...\n",
      "Fetching data for CBRE...\n",
      "Fetching data for MS...\n",
      "Fetching data for CBOE...\n",
      "Fetching data for TDG...\n",
      "Fetching data for GRMN...\n",
      "Fetching data for HIG...\n",
      "Fetching data for TSN...\n",
      "Fetching data for HSIC...\n",
      "Fetching data for DG...\n",
      "Fetching data for L...\n",
      "Fetching data for HCA...\n",
      "Incomplete data for HCA (2470 days). Skipping...\n",
      "Fetching data for WBD...\n",
      "Fetching data for MRO...\n",
      "Fetching data for POOL...\n",
      "Fetching data for ACN...\n",
      "Fetching data for ETR...\n",
      "Fetching data for ZTS...\n",
      "Incomplete data for ZTS (1993 days). Skipping...\n",
      "Fetching data for TXN...\n",
      "Fetching data for EXPE...\n",
      "Fetching data for ED...\n",
      "Fetching data for LRCX...\n",
      "Fetching data for ESS...\n",
      "Fetching data for BRO...\n",
      "Fetching data for EQR...\n",
      "Fetching data for AVY...\n",
      "Fetching data for AVGO...\n",
      "Fetching data for ALLE...\n",
      "Incomplete data for ALLE (1792 days). Skipping...\n",
      "Fetching data for PLD...\n",
      "Fetching data for VZ...\n",
      "Fetching data for MAS...\n",
      "Fetching data for HWM...\n",
      "Incomplete data for HWM (1048 days). Skipping...\n",
      "Fetching data for AME...\n",
      "Fetching data for ICE...\n",
      "Fetching data for CHD...\n",
      "Fetching data for CCL...\n",
      "Fetching data for KO...\n",
      "Fetching data for CME...\n",
      "Fetching data for UNH...\n",
      "Fetching data for WY...\n",
      "Fetching data for BIIB...\n",
      "Fetching data for EBAY...\n",
      "Fetching data for SYY...\n",
      "Fetching data for DD...\n",
      "Fetching data for BWA...\n",
      "Fetching data for RJF...\n",
      "Fetching data for DVN...\n",
      "Fetching data for BDX...\n",
      "Fetching data for GOOGL...\n",
      "Fetching data for HPE...\n",
      "Incomplete data for HPE (1310 days). Skipping...\n",
      "Fetching data for PANW...\n",
      "Incomplete data for PANW (2126 days). Skipping...\n",
      "Fetching data for BXP...\n",
      "Fetching data for SHW...\n",
      "Fetching data for BX...\n",
      "Fetching data for SBAC...\n",
      "Fetching data for GILD...\n",
      "Fetching data for MCK...\n",
      "Fetching data for AAL...\n",
      "Fetching data for ADP...\n",
      "Fetching data for TEL...\n",
      "Fetching data for GM...\n",
      "Fetching data for PSA...\n",
      "Fetching data for RVTY...\n",
      "Fetching data for TER...\n",
      "Fetching data for LLY...\n",
      "Fetching data for HLT...\n",
      "Incomplete data for HLT (1775 days). Skipping...\n",
      "Fetching data for ILMN...\n",
      "Fetching data for GWW...\n",
      "Fetching data for EIX...\n",
      "Fetching data for CPT...\n",
      "Fetching data for BEN...\n",
      "Fetching data for NOC...\n",
      "Fetching data for WRB...\n",
      "Fetching data for MMC...\n",
      "Fetching data for IDXX...\n",
      "Fetching data for DOV...\n",
      "Fetching data for PKG...\n",
      "Fetching data for UPS...\n",
      "Fetching data for BALL...\n",
      "Fetching data for CMA...\n",
      "Fetching data for MPWR...\n",
      "Fetching data for HUBB...\n",
      "Fetching data for AMGN...\n",
      "Fetching data for LDOS...\n",
      "Fetching data for MRK...\n",
      "Fetching data for XOM...\n",
      "Fetching data for SCHW...\n",
      "Fetching data for PFG...\n",
      "Fetching data for STE...\n",
      "Fetching data for QCOM...\n",
      "Fetching data for PPG...\n",
      "Fetching data for FICO...\n",
      "Fetching data for CZR...\n",
      "Incomplete data for CZR (1581 days). Skipping...\n",
      "Fetching data for MCD...\n",
      "Fetching data for TAP...\n",
      "Fetching data for FCX...\n",
      "Fetching data for MPC...\n",
      "Incomplete data for MPC (2396 days). Skipping...\n",
      "Fetching data for PGR...\n",
      "Fetching data for MDLZ...\n",
      "Fetching data for NWSA...\n",
      "Incomplete data for NWSA (1898 days). Skipping...\n",
      "Fetching data for VRTX...\n",
      "Fetching data for DRI...\n",
      "Fetching data for MTB...\n",
      "Fetching data for CNP...\n",
      "Fetching data for LIN...\n",
      "Fetching data for UNP...\n",
      "Fetching data for RL...\n",
      "Fetching data for LULU...\n",
      "Fetching data for CHTR...\n",
      "Fetching data for AMAT...\n",
      "Fetching data for META...\n",
      "Incomplete data for META (2169 days). Skipping...\n",
      "Fetching data for ORLY...\n",
      "Fetching data for ALK...\n",
      "Fetching data for MNST...\n",
      "Fetching data for AFL...\n",
      "Fetching data for CF...\n",
      "Fetching data for SPGI...\n",
      "Fetching data for HBAN...\n",
      "Fetching data for EW...\n",
      "Fetching data for AMCR...\n",
      "Incomplete data for AMCR (2172 days). Skipping...\n",
      "Fetching data for TRV...\n",
      "Fetching data for DE...\n",
      "Fetching data for COF...\n",
      "Fetching data for ROP...\n",
      "Fetching data for RF...\n",
      "Fetching data for NWS...\n",
      "Incomplete data for NWS (1898 days). Skipping...\n",
      "Fetching data for GEN...\n",
      "Data collection complete! Saved to sp500_data.csv.\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T20:29:40.342087Z",
     "start_time": "2025-01-04T20:29:34.974550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load the CSV file\n",
    "file_path = \"sp500_data.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to check the structure\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "\n",
    "missing_summary = data.isnull().sum()\n",
    "print(missing_summary[missing_summary > 0])\n",
    "\n",
    "# Convert 'Date' column to datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "\n",
    "# Sort data by Ticker and Date\n",
    "data = data.sort_values(by=['Ticker', 'Date'])\n",
    "\n",
    "# Group data by ticker and identify the start and end dates for each index\n",
    "ticker_ranges = data.groupby('Ticker')['Date'].agg(['min', 'max']).reset_index()\n",
    "print(\"Ticker ranges:\", ticker_ranges)\n",
    "\n",
    "# Function to filter rows for valid periods\n",
    "def filter_valid_periods(group):\n",
    "    print(f\"Processing group for ticker: {group['Ticker'].iloc[0]}\")  # Debug\n",
    "    required_columns = ['Volume', 'Price_Change']\n",
    "    existing_columns = [col for col in required_columns if col in group.columns]\n",
    "    return group.dropna(subset=existing_columns)\n",
    "\n",
    "# Process data group by group\n",
    "cleaned_groups = []\n",
    "for ticker, group in data.groupby('Ticker'):\n",
    "    cleaned_group = filter_valid_periods(group)\n",
    "    cleaned_groups.append(cleaned_group)\n",
    "\n",
    "# Combine all cleaned groups into a single DataFrame\n",
    "cleaned_data = pd.concat(cleaned_groups, axis=0).reset_index(drop=True)\n",
    "\n",
    "# Count the number of records per ticker\n",
    "ticker_counts = cleaned_data['Ticker'].value_counts()\n",
    "\n",
    "# Remove tickers with fewer than a threshold (e.g., 1000 data points)\n",
    "valid_tickers = ticker_counts[ticker_counts >= 1000].index\n",
    "cleaned_data = cleaned_data[cleaned_data['Ticker'].isin(valid_tickers)]\n",
    "\n",
    "# Save the cleaned data to a CSV file\n",
    "cleaned_data.to_csv(\"cleaned_sp500_data.csv\", index=False)\n",
    "print(\"Cleaned data saved to cleaned_sp500_data.csv.\")\n"
   ],
   "id": "82873a878d153747",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ticker                       Date   Volume  Price_Change\n",
      "0   EQIX  2010-01-04 00:00:00-05:00   576300           NaN\n",
      "1   EQIX  2010-01-05 00:00:00-05:00   681900     -0.009310\n",
      "2   EQIX  2010-01-06 00:00:00-05:00  1397500      0.009121\n",
      "3   EQIX  2010-01-07 00:00:00-05:00   797200     -0.020451\n",
      "4   EQIX  2010-01-08 00:00:00-05:00   432400     -0.004847\n",
      "(1219742, 4)\n",
      "Price_Change    441\n",
      "dtype: int64\n",
      "Ticker ranges:     Ticker                        min                        max\n",
      "0        A  2010-01-04 00:00:00-05:00  2020-12-30 00:00:00-05:00\n",
      "1      AAL  2010-01-04 00:00:00-05:00  2020-12-30 00:00:00-05:00\n",
      "2     AAPL  2010-01-04 00:00:00-05:00  2020-12-30 00:00:00-05:00\n",
      "3      ABT  2010-01-04 00:00:00-05:00  2020-12-30 00:00:00-05:00\n",
      "4     ACGL  2010-01-04 00:00:00-05:00  2020-12-30 00:00:00-05:00\n",
      "..     ...                        ...                        ...\n",
      "436   XRAY  2010-01-04 00:00:00-05:00  2020-12-30 00:00:00-05:00\n",
      "437    YUM  2010-01-04 00:00:00-05:00  2020-12-30 00:00:00-05:00\n",
      "438    ZBH  2010-01-04 00:00:00-05:00  2020-12-30 00:00:00-05:00\n",
      "439   ZBRA  2010-01-04 00:00:00-05:00  2020-12-30 00:00:00-05:00\n",
      "440   ZION  2010-01-04 00:00:00-05:00  2020-12-30 00:00:00-05:00\n",
      "\n",
      "[441 rows x 3 columns]\n",
      "Processing group for ticker: A\n",
      "Processing group for ticker: AAL\n",
      "Processing group for ticker: AAPL\n",
      "Processing group for ticker: ABT\n",
      "Processing group for ticker: ACGL\n",
      "Processing group for ticker: ACN\n",
      "Processing group for ticker: ADBE\n",
      "Processing group for ticker: ADI\n",
      "Processing group for ticker: ADM\n",
      "Processing group for ticker: ADP\n",
      "Processing group for ticker: ADSK\n",
      "Processing group for ticker: AEE\n",
      "Processing group for ticker: AEP\n",
      "Processing group for ticker: AES\n",
      "Processing group for ticker: AFL\n",
      "Processing group for ticker: AIG\n",
      "Processing group for ticker: AIZ\n",
      "Processing group for ticker: AJG\n",
      "Processing group for ticker: AKAM\n",
      "Processing group for ticker: ALB\n",
      "Processing group for ticker: ALGN\n",
      "Processing group for ticker: ALK\n",
      "Processing group for ticker: ALL\n",
      "Processing group for ticker: AMAT\n",
      "Processing group for ticker: AMD\n",
      "Processing group for ticker: AME\n",
      "Processing group for ticker: AMGN\n",
      "Processing group for ticker: AMP\n",
      "Processing group for ticker: AMT\n",
      "Processing group for ticker: AMZN\n",
      "Processing group for ticker: ANSS\n",
      "Processing group for ticker: AON\n",
      "Processing group for ticker: AOS\n",
      "Processing group for ticker: APA\n",
      "Processing group for ticker: APD\n",
      "Processing group for ticker: APH\n",
      "Processing group for ticker: ARE\n",
      "Processing group for ticker: ATO\n",
      "Processing group for ticker: AVB\n",
      "Processing group for ticker: AVGO\n",
      "Processing group for ticker: AVY\n",
      "Processing group for ticker: AWK\n",
      "Processing group for ticker: AXON\n",
      "Processing group for ticker: AXP\n",
      "Processing group for ticker: AZO\n",
      "Processing group for ticker: BA\n",
      "Processing group for ticker: BAC\n",
      "Processing group for ticker: BALL\n",
      "Processing group for ticker: BAX\n",
      "Processing group for ticker: BBWI\n",
      "Processing group for ticker: BBY\n",
      "Processing group for ticker: BDX\n",
      "Processing group for ticker: BEN\n",
      "Processing group for ticker: BG\n",
      "Processing group for ticker: BIIB\n",
      "Processing group for ticker: BIO\n",
      "Processing group for ticker: BK\n",
      "Processing group for ticker: BKNG\n",
      "Processing group for ticker: BKR\n",
      "Processing group for ticker: BLK\n",
      "Processing group for ticker: BMY\n",
      "Processing group for ticker: BR\n",
      "Processing group for ticker: BRO\n",
      "Processing group for ticker: BSX\n",
      "Processing group for ticker: BWA\n",
      "Processing group for ticker: BX\n",
      "Processing group for ticker: BXP\n",
      "Processing group for ticker: C\n",
      "Processing group for ticker: CAG\n",
      "Processing group for ticker: CAH\n",
      "Processing group for ticker: CAT\n",
      "Processing group for ticker: CB\n",
      "Processing group for ticker: CBOE\n",
      "Processing group for ticker: CBRE\n",
      "Processing group for ticker: CCI\n",
      "Processing group for ticker: CCL\n",
      "Processing group for ticker: CDNS\n",
      "Processing group for ticker: CE\n",
      "Processing group for ticker: CF\n",
      "Processing group for ticker: CHD\n",
      "Processing group for ticker: CHRW\n",
      "Processing group for ticker: CHTR\n",
      "Processing group for ticker: CI\n",
      "Processing group for ticker: CINF\n",
      "Processing group for ticker: CL\n",
      "Processing group for ticker: CLX\n",
      "Processing group for ticker: CMA\n",
      "Processing group for ticker: CMCSA\n",
      "Processing group for ticker: CME\n",
      "Processing group for ticker: CMG\n",
      "Processing group for ticker: CMI\n",
      "Processing group for ticker: CMS\n",
      "Processing group for ticker: CNC\n",
      "Processing group for ticker: CNP\n",
      "Processing group for ticker: COF\n",
      "Processing group for ticker: COO\n",
      "Processing group for ticker: COP\n",
      "Processing group for ticker: COR\n",
      "Processing group for ticker: COST\n",
      "Processing group for ticker: CPB\n",
      "Processing group for ticker: CPRT\n",
      "Processing group for ticker: CPT\n",
      "Processing group for ticker: CRL\n",
      "Processing group for ticker: CRM\n",
      "Processing group for ticker: CSCO\n",
      "Processing group for ticker: CSGP\n",
      "Processing group for ticker: CSX\n",
      "Processing group for ticker: CTRA\n",
      "Processing group for ticker: CTSH\n",
      "Processing group for ticker: CVS\n",
      "Processing group for ticker: CVX\n",
      "Processing group for ticker: D\n",
      "Processing group for ticker: DAL\n",
      "Processing group for ticker: DD\n",
      "Processing group for ticker: DE\n",
      "Processing group for ticker: DFS\n",
      "Processing group for ticker: DG\n",
      "Processing group for ticker: DGX\n",
      "Processing group for ticker: DHI\n",
      "Processing group for ticker: DHR\n",
      "Processing group for ticker: DIS\n",
      "Processing group for ticker: DLR\n",
      "Processing group for ticker: DLTR\n",
      "Processing group for ticker: DOV\n",
      "Processing group for ticker: DPZ\n",
      "Processing group for ticker: DRI\n",
      "Processing group for ticker: DTE\n",
      "Processing group for ticker: DUK\n",
      "Processing group for ticker: DVA\n",
      "Processing group for ticker: DVN\n",
      "Processing group for ticker: DXCM\n",
      "Processing group for ticker: EA\n",
      "Processing group for ticker: EBAY\n",
      "Processing group for ticker: ECL\n",
      "Processing group for ticker: ED\n",
      "Processing group for ticker: EFX\n",
      "Processing group for ticker: EG\n",
      "Processing group for ticker: EIX\n",
      "Processing group for ticker: EL\n",
      "Processing group for ticker: ELV\n",
      "Processing group for ticker: EMN\n",
      "Processing group for ticker: EMR\n",
      "Processing group for ticker: EOG\n",
      "Processing group for ticker: EQIX\n",
      "Processing group for ticker: EQR\n",
      "Processing group for ticker: EQT\n",
      "Processing group for ticker: ES\n",
      "Processing group for ticker: ESS\n",
      "Processing group for ticker: ETN\n",
      "Processing group for ticker: ETR\n",
      "Processing group for ticker: EVRG\n",
      "Processing group for ticker: EW\n",
      "Processing group for ticker: EXC\n",
      "Processing group for ticker: EXPD\n",
      "Processing group for ticker: EXPE\n",
      "Processing group for ticker: EXR\n",
      "Processing group for ticker: F\n",
      "Processing group for ticker: FAST\n",
      "Processing group for ticker: FCX\n",
      "Processing group for ticker: FDS\n",
      "Processing group for ticker: FDX\n",
      "Processing group for ticker: FE\n",
      "Processing group for ticker: FFIV\n",
      "Processing group for ticker: FI\n",
      "Processing group for ticker: FICO\n",
      "Processing group for ticker: FIS\n",
      "Processing group for ticker: FITB\n",
      "Processing group for ticker: FMC\n",
      "Processing group for ticker: FRT\n",
      "Processing group for ticker: FSLR\n",
      "Processing group for ticker: FTNT\n",
      "Processing group for ticker: GD\n",
      "Processing group for ticker: GE\n",
      "Processing group for ticker: GEN\n",
      "Processing group for ticker: GILD\n",
      "Processing group for ticker: GIS\n",
      "Processing group for ticker: GL\n",
      "Processing group for ticker: GLW\n",
      "Processing group for ticker: GM\n",
      "Processing group for ticker: GNRC\n",
      "Processing group for ticker: GOOG\n",
      "Processing group for ticker: GOOGL\n",
      "Processing group for ticker: GPC\n",
      "Processing group for ticker: GPN\n",
      "Processing group for ticker: GRMN\n",
      "Processing group for ticker: GS\n",
      "Processing group for ticker: GWW\n",
      "Processing group for ticker: HAL\n",
      "Processing group for ticker: HAS\n",
      "Processing group for ticker: HBAN\n",
      "Processing group for ticker: HD\n",
      "Processing group for ticker: HES\n",
      "Processing group for ticker: HIG\n",
      "Processing group for ticker: HOLX\n",
      "Processing group for ticker: HON\n",
      "Processing group for ticker: HPQ\n",
      "Processing group for ticker: HRL\n",
      "Processing group for ticker: HSIC\n",
      "Processing group for ticker: HST\n",
      "Processing group for ticker: HSY\n",
      "Processing group for ticker: HUBB\n",
      "Processing group for ticker: HUM\n",
      "Processing group for ticker: IBM\n",
      "Processing group for ticker: ICE\n",
      "Processing group for ticker: IDXX\n",
      "Processing group for ticker: IEX\n",
      "Processing group for ticker: IFF\n",
      "Processing group for ticker: ILMN\n",
      "Processing group for ticker: INCY\n",
      "Processing group for ticker: INTC\n",
      "Processing group for ticker: INTU\n",
      "Processing group for ticker: IP\n",
      "Processing group for ticker: IPG\n",
      "Processing group for ticker: IRM\n",
      "Processing group for ticker: ISRG\n",
      "Processing group for ticker: IT\n",
      "Processing group for ticker: ITW\n",
      "Processing group for ticker: IVZ\n",
      "Processing group for ticker: J\n",
      "Processing group for ticker: JBHT\n",
      "Processing group for ticker: JCI\n",
      "Processing group for ticker: JKHY\n",
      "Processing group for ticker: JNJ\n",
      "Processing group for ticker: JNPR\n",
      "Processing group for ticker: JPM\n",
      "Processing group for ticker: K\n",
      "Processing group for ticker: KDP\n",
      "Processing group for ticker: KEY\n",
      "Processing group for ticker: KIM\n",
      "Processing group for ticker: KLAC\n",
      "Processing group for ticker: KMB\n",
      "Processing group for ticker: KMX\n",
      "Processing group for ticker: KO\n",
      "Processing group for ticker: KR\n",
      "Processing group for ticker: L\n",
      "Processing group for ticker: LDOS\n",
      "Processing group for ticker: LEN\n",
      "Processing group for ticker: LH\n",
      "Processing group for ticker: LHX\n",
      "Processing group for ticker: LIN\n",
      "Processing group for ticker: LKQ\n",
      "Processing group for ticker: LLY\n",
      "Processing group for ticker: LMT\n",
      "Processing group for ticker: LNT\n",
      "Processing group for ticker: LOW\n",
      "Processing group for ticker: LRCX\n",
      "Processing group for ticker: LULU\n",
      "Processing group for ticker: LUV\n",
      "Processing group for ticker: LVS\n",
      "Processing group for ticker: LYB\n",
      "Processing group for ticker: LYV\n",
      "Processing group for ticker: MA\n",
      "Processing group for ticker: MAA\n",
      "Processing group for ticker: MAR\n",
      "Processing group for ticker: MAS\n",
      "Processing group for ticker: MCD\n",
      "Processing group for ticker: MCHP\n",
      "Processing group for ticker: MCK\n",
      "Processing group for ticker: MCO\n",
      "Processing group for ticker: MDLZ\n",
      "Processing group for ticker: MDT\n",
      "Processing group for ticker: MET\n",
      "Processing group for ticker: MGM\n",
      "Processing group for ticker: MHK\n",
      "Processing group for ticker: MKC\n",
      "Processing group for ticker: MKTX\n",
      "Processing group for ticker: MLM\n",
      "Processing group for ticker: MMC\n",
      "Processing group for ticker: MMM\n",
      "Processing group for ticker: MNST\n",
      "Processing group for ticker: MO\n",
      "Processing group for ticker: MOH\n",
      "Processing group for ticker: MOS\n",
      "Processing group for ticker: MPWR\n",
      "Processing group for ticker: MRK\n",
      "Processing group for ticker: MRO\n",
      "Processing group for ticker: MS\n",
      "Processing group for ticker: MSCI\n",
      "Processing group for ticker: MSFT\n",
      "Processing group for ticker: MSI\n",
      "Processing group for ticker: MTB\n",
      "Processing group for ticker: MTCH\n",
      "Processing group for ticker: MTD\n",
      "Processing group for ticker: MU\n",
      "Processing group for ticker: NDAQ\n",
      "Processing group for ticker: NDSN\n",
      "Processing group for ticker: NEE\n",
      "Processing group for ticker: NEM\n",
      "Processing group for ticker: NFLX\n",
      "Processing group for ticker: NI\n",
      "Processing group for ticker: NKE\n",
      "Processing group for ticker: NOC\n",
      "Processing group for ticker: NRG\n",
      "Processing group for ticker: NSC\n",
      "Processing group for ticker: NTAP\n",
      "Processing group for ticker: NTRS\n",
      "Processing group for ticker: NUE\n",
      "Processing group for ticker: NVDA\n",
      "Processing group for ticker: NVR\n",
      "Processing group for ticker: NXPI\n",
      "Processing group for ticker: O\n",
      "Processing group for ticker: ODFL\n",
      "Processing group for ticker: OKE\n",
      "Processing group for ticker: OMC\n",
      "Processing group for ticker: ON\n",
      "Processing group for ticker: ORCL\n",
      "Processing group for ticker: ORLY\n",
      "Processing group for ticker: OXY\n",
      "Processing group for ticker: PARA\n",
      "Processing group for ticker: PAYX\n",
      "Processing group for ticker: PCAR\n",
      "Processing group for ticker: PCG\n",
      "Processing group for ticker: PEG\n",
      "Processing group for ticker: PEP\n",
      "Processing group for ticker: PFE\n",
      "Processing group for ticker: PFG\n",
      "Processing group for ticker: PG\n",
      "Processing group for ticker: PGR\n",
      "Processing group for ticker: PH\n",
      "Processing group for ticker: PHM\n",
      "Processing group for ticker: PKG\n",
      "Processing group for ticker: PLD\n",
      "Processing group for ticker: PM\n",
      "Processing group for ticker: PNC\n",
      "Processing group for ticker: PNR\n",
      "Processing group for ticker: PNW\n",
      "Processing group for ticker: PODD\n",
      "Processing group for ticker: POOL\n",
      "Processing group for ticker: PPG\n",
      "Processing group for ticker: PPL\n",
      "Processing group for ticker: PRU\n",
      "Processing group for ticker: PSA\n",
      "Processing group for ticker: PTC\n",
      "Processing group for ticker: PWR\n",
      "Processing group for ticker: QCOM\n",
      "Processing group for ticker: RCL\n",
      "Processing group for ticker: REG\n",
      "Processing group for ticker: REGN\n",
      "Processing group for ticker: RF\n",
      "Processing group for ticker: RHI\n",
      "Processing group for ticker: RJF\n",
      "Processing group for ticker: RL\n",
      "Processing group for ticker: RMD\n",
      "Processing group for ticker: ROK\n",
      "Processing group for ticker: ROL\n",
      "Processing group for ticker: ROP\n",
      "Processing group for ticker: ROST\n",
      "Processing group for ticker: RSG\n",
      "Processing group for ticker: RTX\n",
      "Processing group for ticker: RVTY\n",
      "Processing group for ticker: SBAC\n",
      "Processing group for ticker: SBUX\n",
      "Processing group for ticker: SCHW\n",
      "Processing group for ticker: SEE\n",
      "Processing group for ticker: SHW\n",
      "Processing group for ticker: SJM\n",
      "Processing group for ticker: SLB\n",
      "Processing group for ticker: SNA\n",
      "Processing group for ticker: SNPS\n",
      "Processing group for ticker: SO\n",
      "Processing group for ticker: SPG\n",
      "Processing group for ticker: SPGI\n",
      "Processing group for ticker: SRE\n",
      "Processing group for ticker: STE\n",
      "Processing group for ticker: STLD\n",
      "Processing group for ticker: STT\n",
      "Processing group for ticker: STX\n",
      "Processing group for ticker: STZ\n",
      "Processing group for ticker: SWK\n",
      "Processing group for ticker: SWKS\n",
      "Processing group for ticker: SYK\n",
      "Processing group for ticker: SYY\n",
      "Processing group for ticker: T\n",
      "Processing group for ticker: TAP\n",
      "Processing group for ticker: TDG\n",
      "Processing group for ticker: TDY\n",
      "Processing group for ticker: TECH\n",
      "Processing group for ticker: TEL\n",
      "Processing group for ticker: TER\n",
      "Processing group for ticker: TFC\n",
      "Processing group for ticker: TFX\n",
      "Processing group for ticker: TGT\n",
      "Processing group for ticker: TJX\n",
      "Processing group for ticker: TMO\n",
      "Processing group for ticker: TMUS\n",
      "Processing group for ticker: TPR\n",
      "Processing group for ticker: TRGP\n",
      "Processing group for ticker: TRMB\n",
      "Processing group for ticker: TROW\n",
      "Processing group for ticker: TRV\n",
      "Processing group for ticker: TSCO\n",
      "Processing group for ticker: TSLA\n",
      "Processing group for ticker: TSN\n",
      "Processing group for ticker: TT\n",
      "Processing group for ticker: TTWO\n",
      "Processing group for ticker: TXN\n",
      "Processing group for ticker: TXT\n",
      "Processing group for ticker: TYL\n",
      "Processing group for ticker: UAL\n",
      "Processing group for ticker: UDR\n",
      "Processing group for ticker: UHS\n",
      "Processing group for ticker: ULTA\n",
      "Processing group for ticker: UNH\n",
      "Processing group for ticker: UNP\n",
      "Processing group for ticker: UPS\n",
      "Processing group for ticker: URI\n",
      "Processing group for ticker: USB\n",
      "Processing group for ticker: V\n",
      "Processing group for ticker: VFC\n",
      "Processing group for ticker: VLO\n",
      "Processing group for ticker: VMC\n",
      "Processing group for ticker: VRSK\n",
      "Processing group for ticker: VRSN\n",
      "Processing group for ticker: VRTX\n",
      "Processing group for ticker: VTR\n",
      "Processing group for ticker: VTRS\n",
      "Processing group for ticker: VZ\n",
      "Processing group for ticker: WAB\n",
      "Processing group for ticker: WAT\n",
      "Processing group for ticker: WBA\n",
      "Processing group for ticker: WBD\n",
      "Processing group for ticker: WDC\n",
      "Processing group for ticker: WEC\n",
      "Processing group for ticker: WELL\n",
      "Processing group for ticker: WFC\n",
      "Processing group for ticker: WHR\n",
      "Processing group for ticker: WM\n",
      "Processing group for ticker: WMB\n",
      "Processing group for ticker: WMT\n",
      "Processing group for ticker: WRB\n",
      "Processing group for ticker: WST\n",
      "Processing group for ticker: WTW\n",
      "Processing group for ticker: WY\n",
      "Processing group for ticker: WYNN\n",
      "Processing group for ticker: XEL\n",
      "Processing group for ticker: XOM\n",
      "Processing group for ticker: XRAY\n",
      "Processing group for ticker: YUM\n",
      "Processing group for ticker: ZBH\n",
      "Processing group for ticker: ZBRA\n",
      "Processing group for ticker: ZION\n",
      "Cleaned data saved to cleaned_sp500_data.csv.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T20:33:05.461085Z",
     "start_time": "2025-01-04T20:33:05.091546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clean_data = pd.read_csv(\"cleaned_sp500_data.csv\")\n",
    "print(clean_data.shape)\n",
    "missing_summary = clean_data.isnull().sum()\n",
    "print(missing_summary[missing_summary > 0])\n",
    "\n",
    "# Get unique tickers from the 'Ticker' column\n",
    "unique_tickers = clean_data['Ticker'].unique()\n",
    "\n",
    "# Count the number of unique tickers\n",
    "print(f\"Number of unique tickers: {len(unique_tickers)}\")\n",
    "\n",
    "X = clean_data.drop(columns=['Price_Change'])\n",
    "y = clean_data['Price_Change']\n",
    "print(X.shape, y.shape)\n",
    "print(X.head())\n",
    "print(y.head())"
   ],
   "id": "283de1804598b651",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1219301, 4)\n",
      "Series([], dtype: int64)\n",
      "Number of unique tickers: 441\n",
      "(1219301, 3) (1219301,)\n",
      "  Ticker                       Date   Volume\n",
      "0      A  2010-01-05 00:00:00-05:00  4186031\n",
      "1      A  2010-01-06 00:00:00-05:00  3243779\n",
      "2      A  2010-01-07 00:00:00-05:00  3095172\n",
      "3      A  2010-01-08 00:00:00-05:00  3733918\n",
      "4      A  2010-01-11 00:00:00-05:00  4781579\n",
      "0   -0.010862\n",
      "1   -0.003553\n",
      "2   -0.001296\n",
      "3   -0.000325\n",
      "4    0.000649\n",
      "Name: Price_Change, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e87e27dd8a8437f3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
